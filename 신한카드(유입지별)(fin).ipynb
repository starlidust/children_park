{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium \n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from glob import glob\n",
    "import os\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import geopandas as gpd\n",
    "\n",
    "#한글깨짐 방지\n",
    "plt.rc('font', family = 'Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_2017 = pd.read_csv('E:/python/data/신한카드데이터/내국인 유입지별_2017년_신한_종합.csv').iloc[:,1:]\n",
    "s_2016 = pd.read_csv('E:/python/data/신한카드데이터/내국인 유입지별_2016년_신한_종합.csv').iloc[:,1:]\n",
    "gu = gpd.read_file('E:/python/data/1. 공통참조파일/1. 지역경계 shp파일/통계청/2016년/서울시(집계구)_EPSG_5179.shp',\n",
    "                  encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key값지정\n",
    "code_book = {}\n",
    "code_book[1] = \"20세이하\"\n",
    "code_book[2] = \"21~30세\"\n",
    "code_book[3] = \"31~40세\"\n",
    "code_book[4] = \"41~50세\"\n",
    "code_book[5] = \"51~60세\"\n",
    "code_book[6] = \"61세이상\"\n",
    "code_book['t1'] = \"00시00~05시59\"\n",
    "code_book['t2'] = \"06시00~11시59\"\n",
    "code_book['t3'] = \"12시00~17시59\"\n",
    "code_book['t4'] = \"18시00~23시59\"\n",
    "code_book['F'] = \"여성\"\n",
    "code_book['M'] = \"남성\"\n",
    "code_book[\"1\"] = \"주말\"\n",
    "code_book[\"0\"] = \"주중\"\n",
    "#컬럼명\n",
    "code_book['USECT_CORR'] = \"평균 이용건수\"\n",
    "code_book['AMT_CORR'] = \"평균 이용금액\"\n",
    "code_book['C_PER_AMT'] = \"건별 평균 이용금액\"\n",
    "code_book['AGE_GB'] = \"연령대\"\n",
    "code_book['weekend'] = \"주말\"\n",
    "code_book['SEX_CCD'] = \"성별\"\n",
    "code_book['TM'] = \"시간대\"\n",
    "code_book['SB_UPJONG'] = '업종'\n",
    "\n",
    "#업종추가\n",
    "upjong = pd.read_csv('./data/041. 서울시 15-17년 업종별 내외국인 신한카드 매출데이터/2. 파일데이터/신한카드_내국인_업종코드.csv',\n",
    "                    encoding= 'cp949')\n",
    "upjong['UPJONG_NM'] = upjong['UPJONG_NM'].apply(lambda x : x.replace('/','&')) \n",
    "upjong.index = upjong.UPJONG\n",
    "del upjong['UPJONG']\n",
    "upjong_dict = upjong.to_dict()\n",
    "upjong_dict = upjong_dict['UPJONG_NM']\n",
    "code_book.update(upjong_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3260210, 10), (632094, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C_SGG_CD에 결측이 있으나, 이는 오류가 아님 (서울경기 외 다른 지역 시도)\n",
    "s_2017.shape, s_2017[s_2017.C_SGG_CD.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gu_merge(df):\n",
    "    #집계구 코드 불러오고 발라내기 \n",
    "    gwang_code = pd.read_csv('./data/광진구_행정동코드.csv',encoding = 'cp949')\n",
    "    gwangjin_dong = gwang_code['행정동'].values\n",
    "    gwangjin_gu = gu[gu.ADM_NM.isin(gwangjin_dong)]\n",
    "\n",
    "    # 각 집계구의 중심점\n",
    "    gwangjin_gu['center_point'] = gwangjin_gu.geometry.apply(lambda x : x.centroid)\n",
    "    gwangjin_gu['center_x'] = gwangjin_gu.center_point.apply(lambda point : point.x)\n",
    "    gwangjin_gu['center_y'] = gwangjin_gu.center_point.apply(lambda point : point.y)\n",
    "    \n",
    "    #데이터 결합\n",
    "    df.BLOCK_ID = df.BLOCK_ID.astype(str) #타입이 다르므로 통일\n",
    "    merged = gwangjin_gu.merge(df, how = 'outer',left_on = 'TOT_REG_CD',right_on = 'BLOCK_ID')\n",
    "    \n",
    "    #결측제외 (집계구 개수와, 데이터의 집계구 개수가 다름)\n",
    "    merged = merged[~(merged.BLOCK_ID.isna())]\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "s_2017_gu = gu_merge(s_2017)\n",
    "s_2016_gu = gu_merge(s_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_park(df):\n",
    "    '''범위내 축소 \n",
    "    \n",
    "    '''\n",
    "    # 대공원주변 범위\n",
    "    ymin,ymax = 1949300, 1951100\n",
    "    xmin,xmax = 962000, 964100\n",
    "    \n",
    "    target = df[(df.center_x >= xmin)&(df.center_x <= xmax)]\n",
    "    target = target[(target.center_y >= ymin)&(target.center_y <= ymax)]\n",
    "    \n",
    "    #건대상권 제외\n",
    "    gun_x, gun_y = 962250, 1949600\n",
    "    target = target[~((target.center_x <= gun_x)&((target.center_y <= gun_y)))]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_2016 = near_park(s_2016_gu)\n",
    "near_2017 = near_park(s_2017_gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(df):\n",
    "    '''BLOCK_ID값으로 label매칭\n",
    "    '''\n",
    "    label = pd.read_csv('./data/신한카드데이터/블럭별 클러스터라벨.csv')\n",
    "    label['BLOCK_ID'] = label.BLOCK_ID.astype(str)\n",
    "    labeled = pd.merge(df, label,how= 'left',on = 'BLOCK_ID')\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_2016_lb = labeling(near_2016)\n",
    "near_2017_lb = labeling(near_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekend(df):\n",
    "    #주말구분\n",
    "    df.loc[(df.DAW_CCD == 1)|(df.DAW_CCD == 7),'weekend'] = \"1\"\n",
    "    df.loc[~((df.DAW_CCD == 1)|(df.DAW_CCD == 7)),'weekend'] = \"0\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_2016_lb = add_weekend(near_2016_lb)\n",
    "near_2017_lb = add_weekend(near_2017_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측값을 임의의 숫자로 체워둠\n",
    "near_2016_lb= near_2016_lb.fillna('0')\n",
    "near_2017_lb= near_2017_lb.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 좌표 데이터 기억\n",
    "geo_2017 = near_2016_lb[['BLOCK_ID','geometry']]\n",
    "geo_2016 = near_2017_lb[['BLOCK_ID','geometry']]\n",
    "\n",
    "geo_2017 = geo_2017.drop_duplicates()\n",
    "geo_2016 = geo_2016.drop_duplicates()\n",
    "\n",
    "geo_m = pd.concat([geo_2017,geo_2016])\n",
    "geo_m = geo_m.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_cluster(df):\n",
    "    #11개 구역 클러스터링 한 내역\n",
    "    label_line = gpd.read_file('E:/python/data/신한카드데이터/라벨별_명칭_geo값.shp')\n",
    "    \n",
    "    cluster_df = df[['SB_UPJONG','TS_YM','TM','labels','C_SIDO_CD','C_SGG_CD','weekend','USECT_CORR','AMT_CORR']]\n",
    "    cluster_g = cluster_df.groupby(['SB_UPJONG','TS_YM','TM','C_SIDO_CD','C_SGG_CD','labels','weekend'])['USECT_CORR','AMT_CORR'].sum().reset_index()\n",
    "    cluster_g = cluster_g.merge(label_line, how= 'left')\n",
    "    cluster_g = gpd.GeoDataFrame(cluster_g)\n",
    "    \n",
    "    return cluster_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_2016 = agg_cluster(near_2016_lb)\n",
    "c_2017 = agg_cluster(near_2017_lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  유입지코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_name(df):\n",
    "    '''\n",
    "    유입지코드 불러와서 매칭시키기\n",
    "    '''\n",
    "    comefrom = pd.read_csv('E:/python/data/041. 서울시 15-17년 업종별 내외국인 신한카드 매출데이터/2. 파일데이터/신한카드_내국인_유입지코드.csv',\n",
    "                      encoding = 'cp949')\n",
    "    comefrom =comefrom.fillna('0')\n",
    "    #딕셔너리화 \n",
    "    comefrom['CODE'] = comefrom['C_SIDO_CD'].astype(str)+\"_\"+comefrom['C_SGG_CD'].astype(int).astype(str)\n",
    "    comefrom['NAME'] = comefrom['C_SIDO_NM']+\"_\"+comefrom['C_SGG_NM']\n",
    "    C_SIDO_dict = comefrom[['CODE','NAME']]\n",
    "    C_SIDO_dict = C_SIDO_dict.set_index('CODE')\n",
    "    C_SIDO_dict = C_SIDO_dict.to_dict()['NAME']\n",
    "\n",
    "    \n",
    "    #매칭\n",
    "    df['CODE'] = df.C_SIDO_CD.astype(int).astype(str) +'_'+df.C_SGG_CD.astype(int).astype(str)\n",
    "    df['C_NAME'] = df.CODE.apply(lambda x : C_SIDO_dict[x])\n",
    "    df['C_NAME'] = df['C_NAME'].apply(lambda x : x.replace('_0',''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_2016_c = encoding_name(c_2016)\n",
    "c_2017_c = encoding_name(c_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comefrom_rate_b(df):\n",
    "    #저장위치\n",
    "    path = './output/신한카드/유입지비율_월평균'\n",
    "    os.makedirs(path,exist_ok = True)\n",
    "    \n",
    "    year = str(df['TS_YM'][0])[:4]\n",
    "    \n",
    "    if year == 2016:\n",
    "        divid = 12\n",
    "    else:\n",
    "        divid = 11\n",
    "    \n",
    "    sample = (df.groupby(['names','C_NAME'])['USECT_CORR','AMT_CORR'].sum()/divid).reset_index()\n",
    "    #건별 평균 이용금액\n",
    "    sample['C_PER_AMT'] = round(sample['AMT_CORR']/sample['USECT_CORR'],2)\n",
    "    base_top10 = pd.DataFrame()\n",
    "    \n",
    "    for c in ['AMT_CORR','USECT_CORR','C_PER_AMT']:\n",
    "        for name in sample.names.unique():\n",
    "            sample_part = sample[sample.names == name]\n",
    "            sample_part = sample_part.set_index('C_NAME')[c]\n",
    "            sample_part = round((sample_part/sample_part.sum())*100,2).sort_values(ascending= False)\n",
    "            sample_part.to_csv(f'{path}/{year}_{name}_{code_book[c]}에 따른 유입지비율.csv',encoding = 'cp949')\n",
    "            \n",
    "            #상위 10개조합\n",
    "            top10 = pd.DataFrame(sample_part.head(10)).reset_index()\n",
    "            top10.columns = [name, name]\n",
    "            base_top10 = pd.concat([base_top10,top10],axis=1)\n",
    "        base_top10.to_csv(f'{path}/{year}_{code_book[c]}에 따른 유입지top10.csv',encoding = 'cp949')\n",
    "        #리셋\n",
    "        base_top10 = pd.DataFrame()\n",
    "        \n",
    "    \n",
    "    return base_top10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "base_top10_2016 = comefrom_rate_b(c_2016_c)\n",
    "base_top10_2017 = comefrom_rate_b(c_2017_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5(df,value_col):\n",
    "    #저장위치\n",
    "    year = str(df['TS_YM'].iloc[0])[:4]\n",
    "    \n",
    "    if year == 2016:\n",
    "        divid = 12\n",
    "    else:\n",
    "        divid = 11\n",
    "    \n",
    "    sample = (df.groupby(['names','C_NAME'])['USECT_CORR','AMT_CORR'].sum()/divid).reset_index()\n",
    "    #건별 평균 이용금액\n",
    "    sample['C_PER_AMT'] = round(sample['AMT_CORR']/sample['USECT_CORR'],2)\n",
    "    \n",
    "    top_5_dict = {}\n",
    "    for name in sample.names.unique():\n",
    "        sample_part = sample[sample.names == name]\n",
    "        sample_part = sample_part.set_index('C_NAME')[value_col]\n",
    "        sample_part = round((sample_part/sample_part.sum())*100,2).sort_values(ascending= False)\n",
    "        top_5_dict[name] = sample_part.head(5).index.values\n",
    "    \n",
    "    return top_5_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_2016 = get_top5(c_2016_c, \"AMT_CORR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top5의 업종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'names'\n",
    "hue = 'SB_UPJONG'\n",
    "value_col = 'AMT_CORR'\n",
    "name = '구의문'\n",
    "color_bound = None\n",
    "cmap = 'tab20'\n",
    "special_legend = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_upjong1 = ['한식','일식&중식&양식','제과점','커피전문점',\n",
    "#            '패스트푸드','기타요식']\n",
    "# s_upjong2 = ['유흥','음&식료품','의류&잡화','스포츠&문화&레저',\n",
    "#             '교육용품','가전가구','자동차']\n",
    "s_upjong1 = ['sb01','sb02','sb03','sb04','sb05','sb06']\n",
    "s_upjong2 = ['sb07','sb09','sb10','sb11','sb18','sb20','sb21'] #sb17 유아교육을 제외하고도 실험\n",
    "s_upjong_m = s_upjong1 + s_upjong2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_upjong(df, hue, value_col, color_bound = None,special_legend = None,cmap = 'tab20',part = None):\n",
    "    \n",
    "    path = './output/신한카드/유입지_상위_5개지역_업종'\n",
    "    os.makedirs(path,exist_ok = True)\n",
    "    year = str(df['TS_YM'].iloc[0])[:4]\n",
    "    \n",
    "    if year == 2016:\n",
    "        divid = 12\n",
    "    else:\n",
    "        divid = 11\n",
    "    #특정값만\n",
    "    if part != None:\n",
    "        df = df[df[hue].isin(part)]\n",
    "        \n",
    "    grouped = (df.groupby(['names','C_NAME',hue])['USECT_CORR','AMT_CORR'].sum()/12).reset_index()\n",
    "    grouped['C_PER_AMT'] = grouped['AMT_CORR']/grouped['USECT_CORR']\n",
    "    \n",
    "    #top5\n",
    "    top5_dict= get_top5(df, value_col)\n",
    "    \n",
    "    for name in grouped.names.unique():\n",
    "        c_grouped = grouped[grouped.names == name] #특정클러스터\n",
    "        top5 =top5_dict[name]\n",
    "        c_grouped = c_grouped[c_grouped.C_NAME.isin(top5)]\n",
    "        grouped_pivot = c_grouped.pivot_table(index= hue ,columns= \"C_NAME\",values = value_col, \n",
    "                                       aggfunc = 'sum',fill_value=0)\n",
    "\n",
    "        #비율로 변경\n",
    "        sumed = grouped_pivot.sum(axis= 0).values\n",
    "        grouped_pivot = (grouped_pivot/sumed)*100\n",
    "\n",
    "        #값 누적(누적막대그래프를 그리기 위해)\n",
    "        for i in range(1,len(grouped_pivot)):\n",
    "            grouped_pivot.values[i] = grouped_pivot.values[i-1]+ grouped_pivot.values[i]\n",
    "\n",
    "        label_num = grouped_pivot.shape[0] #hue개수\n",
    "\n",
    "        #사용할 색상\n",
    "        c_min = 0.0\n",
    "        c_max = 1.0\n",
    "        if color_bound != None:\n",
    "            c_min = color_bound[0]\n",
    "            c_max = color_bound[1]\n",
    "        color_list = [plt.cm.get_cmap(cmap)(c) for c in np.linspace(c_min, c_max,label_num)]  #np.linspace 범위내 동일한 간격으로 값 생성\n",
    "\n",
    "        legends = list(grouped_pivot.index.values) \n",
    "\n",
    "        #코드북에 있는 값 가져오기\n",
    "        for i, l_v in enumerate(legends):\n",
    "            legends[i] = code_book[l_v]\n",
    "        legends.reverse()\n",
    "\n",
    "\n",
    "        #특정범례 지정시\n",
    "        if special_legend != None:\n",
    "            legends = special_legend\n",
    "\n",
    "        #그리기 (누적값이 높은 row순으로 차례로 그려나감 - 겹치는 형태)\n",
    "        y_value = grouped_pivot.columns #누적을 그릴 컬럼명\n",
    "        x_value = grouped_pivot.values #누적되어질 값\n",
    "        plt.figure(figsize=(12,8))\n",
    "        for i in range(len(grouped_pivot)):\n",
    "            ax = plt.barh(y_value, x_value[label_num-1-i],color= color_list[i])\n",
    "\n",
    "        plt.xticks(size = 12)\n",
    "        plt.yticks(size = 12)\n",
    "        plt.title(f'{year}_{name}_상위5개 유입지_{code_book[hue]}_{code_book[value_col]}')\n",
    "        plt.legend(legends,loc = 'center left',bbox_to_anchor=(1, 0.5),fontsize = 12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{path}/{year}_{name}_상위5개 유입지_{code_book[hue]}_{code_book[value_col]}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_upjong(c_2016_c,\"SB_UPJONG\",\"AMT_CORR\",part = s_upjong1)\n",
    "top5_upjong(c_2016_c,\"SB_UPJONG\",\"USECT_CORR\",part = s_upjong1)\n",
    "top5_upjong(c_2016_c,\"SB_UPJONG\",\"C_PER_AMT\",part = s_upjong1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_upjong(c_2016_c,\"SB_UPJONG\",\"AMT_CORR\",part = s_upjong2)\n",
    "top5_upjong(c_2016_c,\"SB_UPJONG\",\"USECT_CORR\",part = s_upjong2)\n",
    "top5_upjong(c_2016_c,\"SB_UPJONG\",\"C_PER_AMT\",part = s_upjong2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
